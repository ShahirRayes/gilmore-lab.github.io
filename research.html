<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Gilmore Lab</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="publications.html">Publications</a>
</li>
<li>
  <a href="parents.html">Parents</a>
</li>
<li>
  <a href="participants.html">Participants</a>
</li>
<li>
  <a href="students.html">Students</a>
</li>
<li>
  <a href="lab-meetings.html">Lab mtgs</a>
</li>
<li>
  <a href="site-info.html">Site info</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="active-projects" class="section level1">
<h1>Active Projects</h1>
<div id="developmental-dynamics-of-optic-flow-processing" class="section level2">
<h2>Developmental Dynamics of Optic Flow Processing</h2>
<p><img src="images/fesi-2014.jpg" alt="Brain activity" /> <img src="images/optic-flow.jpg" alt="Optic flow" /></p>
<p>Visual motion provides humans and animals with information about their own movement through 3D space and about the structure of the environment – the objects, surfaces, and other animals that it may contain. How the human brain processes complex motion information poses an as-yet unanswered question. This project focuses on characterizing how sensitivity to visual motion emerges in the developing human brain: how brain (EEG) responses to patterns of ego- and object motion emerge, how they develop from infancy through childhood into adulthood, how specific changes in cortical circuitry might account for the observed patterns, and how behavioral sensitivity to motion corresponds to neural activation. The studies compare brain responses and behavioral discrimination patterns in infants, children, and adults to the same types of ego- and object motion. The studies also involve an effort to measure or simulate the statistics of optic flow experienced by infant, child, and adult observers in complex, natural environments using computer vision methods.</p>
<p><strong>Publications</strong></p>
<ul>
<li>Gilmore, R.O., Thomas, A.L., &amp; Fesi, J.D (2016). Children’s brain responses to optic flow vary by pattern type and motion speed. <em>PLoS ONE</em>. <a href="http://doi.org/10.1371/journal.pone.0157911">doi: 10.1371/journal.pone.0157911</a>. Materials on Databrary at <a href="http://doi.org/10.17910/B7QG6W" class="uri">http://doi.org/10.17910/B7QG6W</a>.</li>
<li>Gilmore, R.O., Raudies, F., &amp; Jayaraman, S. (2015). What Accounts for Developmental Shifts in Optic Flow Sensitivity? <em>Proceedings of the IEEE International Conference on Development and Learning and Epigenetic Robotics</em>. <a href="http:/doi.org/10.1109/DEVLRN.2015.7345450">doi:10.1109/DEVLRN.2015.7345450</a>. Materials on Databrary at <a href="http://dx.doi.org/10.17910/B7988V">doi:10.17910/B7988V</a>.</li>
<li>Fesi, J.F., Thomas, A.L., &amp; Gilmore, R.O. (2014). Cortical responses to optic flow and motion contrast across patterns and speeds. <em>Vision Research</em>, 100, 56–71. <a href="http://dx.doi.org/10.1016/j.visres.2014.04.004">doi:10.1016/j.visres.2014.04.004</a>. <a href="https://databrary.org/volume/49">Materials on Databrary</a>.</li>
<li>Raudies, F. &amp; Gilmore, R.O. (2014). Visual motion priors differ for infants and mothers. <em>Neural Computation</em>, <em>26</em>(11), 2652-2668. <a href="http://dx.doi.org/10.1162/NECO_a_00645">doi:10.1162/NECO_a_00645</a>.</li>
<li>Raudies, F., Gilmore, R.O., Kretch, K.S., Franchak, J.M, &amp; Adolph, K.E. (2012). Understanding the development of motion processing by characterizing optic flow experienced by infants and their mothers. <em>Proceedings of the IEEE International Conference on Development and Learning</em>. <a href="http://dx.doi.org/10.1109/DevLrn.2012.6400584">doi:10.1109/DevLrn.2012.6400584</a>.</li>
</ul>
<p><strong>Presentations</strong></p>
<ul>
<li>Gilmore, R.O., Fared, D.A., Dexheimer, M.G., &amp; Seisler, A.R. (2016, November). The appearance and disappearance of visual forms defined by differential motion evokes distinctive EEG responses in school-age children. Presentation at the Society for Neuroscience meeting in San Diego, CA. <a href="https://github.com/gilmore-lab/child-motion-form/blob/master/pubs/sfn-16-poster/poster_landscape.pdf">PDF</a>.</li>
<li>Gilmore, R.O. (2016, October). Go with the flow: The development of behavioral sensitivity and brain responses to optic flow. Talk at the Penn State Action club meeting. <a href="http://rawgit.com/gilmore-lab/psu-action-club-2016-10-28/master/gilmore-action-club.html">HTML slides</a>.</li>
<li>Jayaraman, S., Gilmore, R.O., &amp; Raudies, F. (2016, May). Changes in early optic flow experiences across development and culture. Talk at the International Congress on Infant Studies (ICIS) in New Orleans, LA. <a href="https://rawgit.com/gilmore-lab/ICIS-2016-New-Orleans/master/jayaraman-gilmore-raudies-ICIS-2016.html">HTML slides</a>.</li>
<li>Gilmore, R.O. (2016, September). Open science practices have made my work better. Talk at the Penn State Psychology Cognitive Area brown bag. <a href="https://cdn.rawgit.com/psu-psychology/cognitive/master/brown-bag/2015-09-09-gilmore/cog-bbag-2015-09-09.html">HTML slides</a>.</li>
<li>Adamiak, W., Thomas, A.L., Patel, S.M., &amp; Gilmore. R.O. (2015, May). Adult observers’ sensitivity to optic flow varies by pattern and speed. Poster presented at the Vision Sciences Society meeting, St. Pete’s Beach, FL. <a href="doi:10.1167/15.12.1008" class="uri">doi:10.1167/15.12.1008</a>. <a href="../pdfs/adamiak-etal-vss-2015.pdf">PDF</a>. <a href="http://databrary.org/volume/73">Materials on Databrary</a>.</li>
<li>Raudies, F. &amp; Gilmore, R.O. (2014, May). An analysis of optic flow experienced by infants during natural activities. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. Journal of Vision, 14(10). 226. <a href="doi:10.1167/14.10.226" class="uri">doi:10.1167/14.10.226</a>. <a href="../pdf/raudies-etal-vss-2014.pdf">PDF</a></li>
<li>Thomas, A.L., Fesi, J.D. &amp; Gilmore, R.O. (2014, May). Temporal and speed tuning in brain Responses to local and global motion patterns. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. Journal of Vision, 14(10). 482. <a href="doi:10.1167/14.10.482" class="uri">doi:10.1167/14.10.482</a>.</li>
<li>Fesi, J.D., Thomas, A.L., &amp; Gilmore, R.O. (2012, October). Distinct space-time sampling thresholds of VEP responses to optic flow. Poster presented at the Society for Neuroscience meeting, New Orleans, LA. <a href="../pdf/fesi-etal-sfn-2012.pdf">PDF</a></li>
<li>Gilmore, R.O., Raudies, F., Kretch, K.S., Franchak, J.M., &amp; Adolph, K.E. (2012, June). Do you see what I see? Comparing optic flow experienced by infants and their mothers. Poster presented at the International Conference on Infant Studies, Minneapolis, MN. <a href="../pdf/gilmore-etal-icis-2012.pdf">PDF</a>.</li>
<li>Fesi, J.D., Stiffler, J.R., &amp; Gilmore, R.O. (2012, May). Speed tuning of cortical responses to 2D figures defined by motion contrast is non-uniform across contrast types. Poster presented at the Vision Sciences Society meeting, Naples, FL.</li>
<li>Thomas, A.L., Mancino, A.C., Elnathan, H.C., Fesi, J.D., Hwang, K.R., &amp; Gilmore, R.O. (2012, May). Children’s cortical responses to optic flow patterns show differential tuning by pattern type, speed, scalp location, and age group. Poster presented at the Vision Sciences Society meeting, Naples, FL. <a href="../pdf/thomas-etal-vss-2012.pdf">PDF</a>.</li>
<li>Gilmore, R.O., Raudies, F., Kretch, K.S., Franchak, J.M., &amp; Adolph, K.E. (2012, May). Patterns of optic flow experienced by infants and their mothers during locomotion. Poster presented at the Vision Sciences Society meeting, Naples, FL. <a href="../pdf/gilmore-etal-vss-2012.pdf">PDF</a>.</li>
<li>Raudies, F., Kretch, K.S., Franchak, J.M., Mingolla, E., Gilmore, R.O., &amp; Adolph, K.E. (2012, May). Where do mothers point their head when they walk and where do babies point their head when they are carried? Poster presented at the Vision Sciences Society meeting, Naples, FL. <a href="../pdf/raudies-etal-vss-2012.pdf">PDF</a>.</li>
</ul>
<p><strong>Materials</strong></p>
<ul>
<li><a href="http://databrary.org/volume/73" class="uri">http://databrary.org/volume/73</a></li>
<li><a href="http://dx.doi.org/10.17910/B7988V" class="uri">http://dx.doi.org/10.17910/B7988V</a></li>
</ul>
<p><strong>Collaborators</strong></p>
<ul>
<li>Florian Raudies, Hewlett-Packard Research</li>
<li>Swapnaa Jayaraman, Indiana University</li>
<li>Amanda Thomas, Swarthmore College</li>
<li>Jeremy Fesi, U.S. Marine Research</li>
</ul>
<p><strong>Support</strong></p>
<p>This project was supported by the National Science Foundation under grant <a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1147440">BCS-1147440</a>.</p>
</div>
<div id="computational-symmetry" class="section level2">
<h2>Computational Symmetry</h2>
<p><img src="images/symmetry-sample-1.png" alt="Symmetric image" /> <img src="images/symmetry-sample-2.png" alt="Symmetric image" /></p>
<p>The ability to sense regular or near-regular patterns serves critical biological needs and is equally important for computer vision and machine intelligence. Despite wide variation in the types of regularity present in natural images, research on human and computer processing of pattern regularity has focused primarily on detecting bilateral reflection symmetry, using largely atheoretical approaches. The goals of this interdisciplinary research are to i) use principles of group theory to develop a conceptual framework for understanding regularity perception and brain activation in humans, and ii) to design general computer-based symmetry detection algorithms that can operate at a level of practical usability.</p>
<p><strong>Presentations</strong></p>
<ul>
<li>Vedak, S.C., Gilmore, R.O., Kohler, P.J., Liu, Y., &amp; Norcia, A.M. (2015, May). The salience of low-order visual features in highly self-similar wallpaper groups. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. <a href="../pdfs/vedak-etal-vss-2015.pdf">PDF</a>. <a href="http://databrary.org/volume/77">Materials on Databrary</a>.</li>
<li>Thomas, A.L., Gilmore, R.O., Norcia, A.M., Liu, Y., Fesi, J.D., Hwang, K.D., Stitt, J., &amp; Liu, J. (2012, October). Visual patterns with rotational symmetry activate distinct cortical regions. Poster presented at the Society for Neuroscience meeting, New Orleans, LA.</li>
</ul>
<p><strong>Collaborators</strong></p>
<ul>
<li>Yanxi Liu, Penn State Computer Science &amp; Engineering</li>
<li>Anthony Norcia, Stanford University, Department of Psychology</li>
</ul>
<p><strong>Support</strong></p>
<p>This project is supported by the National Science Foundation under grant <a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1248076">IIS-1248076</a>.</p>
<p><img src="http://databrary.org/theme/img/logo/databrary.png"></p>
<p>The <a href="http://databrary.org">Databrary Project</a> aims to increase scientific transparency and accelerate discovery in developmental science by building the infrastructure for researchers to share video data and related meta-data. The project has five specific aims:</p>
<ul>
<li>Create a web-based <a href="http://databrary.org">data library</a> for sharing and preserving video data and associated meta-data.</li>
<li>Create participant and contributor/user standards that enable open sharing of video data while limiting access to authorized users to ensure participant confidentiality.</li>
<li>Expand the free, open source video coding software, <a href="http://datavyu.org">Datavyu</a> to enable coding, exploring, and analyzing video data.</li>
<li>Build a data management system to support data sharing within labs, among collaborators, and in the Databrary repository.</li>
<li>Transform the culture of developmental science by building a community of researchers committed to open video data sharing.</li>
</ul>
<p>Databrary is an <a href="http://github.com/databrary">open-source</a> software project. Penn State is one of the major “nodes”, with a large number of authorized users.</p>
<p><strong>Publications</strong></p>
<ul>
<li>Gilmore, R.O., &amp; Adolph, K.E. (2017, February 6). Video can make science more open, transparent, robust, and reproducible. Retrieved from <a href="http://osf.io/3kvp7" class="uri">http://osf.io/3kvp7</a>.</li>
<li>Gilmore, R.O., Diaz, M.T., Wyble, B.A., &amp; Yarkoni, T. (in press). Progress toward openness, transparency, and reproducibility in cognitive neuroscience. <em>Annals of the New York Academy of Sciences</em>.</li>
<li>Gilmore, R.O., &amp; Adolph, K.E. (in press). Open sharing of research video: Breaking the boundaries of the research team, in <em>Advancing Social and Behavioral Health Research through Cross-disciplinary Team Science: Principles for Success</em>. Hall, Kara, Croyle, R., &amp; Vogel, A. (Eds.). Springer.</li>
<li>Gilmore, R.O., Adolph, K.E., &amp; Millman, D.S. (2016). Curating identifiable data for sharing: The Databrary project. In Proceedings of the 2016 New York Scientific Data Summit. <a href="https://github.com/databrary/presentations/blob/master/nysds-2016/gilmore-adolph-millman-nysds-2016.pdf">PDF of paper</a>.</li>
<li>Gilmore, R.O., Adolph, K.E., &amp; Millman, D.S. (2016). Transforming education research through open video data sharing. <em>Advances in Engineering Education</em>, <em>5</em>(2). <a href="http://advances.asee.org/publication/transforming-education-research-through-open-video-data-sharing/">HTML</a>.</li>
<li>Gilmore, R.O. (2016). From big data to deep insight in developmental science. <em>Wiley Interdisciplinary Reviews Cognitive Science</em>. <a href="http://doi.org/10.1001/wcs.1379">DOI: 10.1002/wcs.1379</a>.</li>
<li>Gordon, A., Millman, D.S., Steiger, L., Adolph, K.E., &amp; Gilmore, R.O. (2015). Researcher-library collaborations: Data repositories as a service for researchers. <em>Journal of Librarianship and Scholarly Communication</em>. <a href="http://dx.doi.org/10.7710/2162-3309.1238">doi:10.7710/2162-3309.1238</a>.</li>
<li>Adolph, K.E., Gilmore, R.O., Freeman, C., Sanderson, P., &amp; Millman, D. (2012). Toward Open Behavioral Science, <em>Psychological Inquiry: An International Journal for the Advancement of Psychological Theory</em>, <em>23</em>(3), 244-247. <a href="http://dx.doi.org/10.1080/1047840X.2012.705133">doi:10.1080/1047840X.2012.705133</a>.</li>
</ul>
<p><strong>Presentations</strong></p>
<ul>
<li>Gilmore, R.O. (2017, February 22). A Databservatory for human behavior. Talk given at the Cognitive Area Brown Bag. <a href="https://gilmore-lab.github.io/cog-bbag-talk-2017-02-22">HTML slides</a>.</li>
<li>Gilmore, R.O. (2017, January 31). An -ome of our own: Toward a more reproducible, robust, and insightful science of human behavior. Talk given to the Social Data Analytics (SoDA) 501 students. Penn State University. <a href="http://gilmore-lab.github.io/soda-2017-01-31">HTML slides</a></li>
<li>Gilmore, R.O. (2016, October). The future of big data in developmental science. Talk given at a meeting of the Penn State Child Study Center (CSC) faculty. <a href="http://rawgit.com/gilmore-lab/psu-child-study-ctr-talk-2016-10-28/master/gilmore-csc-talk.html">HTML slides</a>.</li>
<li>Gilmore, R.O. (2016, September). Donald Rumsfeld and the promise of a ‘big data’ science of human behavior. Talk given at a meeting of the Stochastic Modeling and Computational Statistics (SMACS) group, Department of Statistics. <a href="https://rawgit.com/gilmore-lab/psu-stats-smacs-2016-talk/master/gilmore-smacs-2016-09-02.html">HTML slides</a>.</li>
<li>Gilmore, R.O., Adolph, K.E., &amp; Millman, D.S. (2016, August). Curating identifiable data for sharing: The Databrary project. In Proceedings of the 2016 New York Scientific Data Summit. <a href="https://rawgit.com/databrary/presentations/master/nysds-2016/gilmore-nysds-2016.html">HTML slides</a>. <a href="https://github.com/databrary/presentations/blob/master/nysds-2016/gilmore-adolph-millman-nysds-2016.pdf">PDF of paper</a>.</li>
<li>Gilmore, R.O., Adolph, K.E., &amp; Millman, D. (2016, May). Video doesn’t lie: Reproducible workflows with Databrary. Talk given at the NYU Data Science Center <a href="https://reproduciblescience.org/nyu/events/reproducibility-symposium-2016/schedule/">Symposium on Reproducibility</a>. <a href="https://rawgit.com/databrary/presentations/master/nyu-data-science-reproducibility-16/be-bold.html#1">HTML slides</a></li>
<li>Gilmore, R.O., Adolph, K.E., Millman, D.S., Steiger, L., &amp; Simon, D.A. (2015, May). Sharing displays and data from vision science research with Databrary. Poster presented at the Vision Sciences Society meeting, St. Pete Beach, FL. <a href="../pdfs/gilmore-etal-vss-2015.pdf">PDF</a>.</li>
</ul>
<p><strong>Collaborators</strong></p>
<ul>
<li>Karen Adolph, New York University, Co-Principal Investigator and Project Director</li>
<li>David Millman, New York University, Co-Investigator.</li>
</ul>
<p><strong>Support</strong></p>
<p>This project is supported by the U.S. National Science Foundation (NSF) Grant No. <a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1238599">BCS-1238599</a> and the Eunice Kennedy Shriver National Institute of Child Health and Human Development under Cooperative Agreement <a href="http://projectreporter.nih.gov/project_info_description.cfm?aid=8531595&amp;icde=15908155&amp;ddparam=&amp;ddvalue=&amp;ddsub=&amp;cr=1&amp;csb=default&amp;cs=ASC">1-U01-HD-076595-01</a>.</p>
</div>
<div id="the-proximal-emotional-environment-project-peep" class="section level2">
<h2>The Proximal Emotional Environment Project (PEEP)</h2>
<p>A 5-year-old overhears her parents arguing loudly in the next room. She may not understand why they are arguing, but she realizes something is wrong because she perceives anger in their voices. Exposure to interpersonal conflict is consistently associated with less skillful emotion regulation in children although the mechanisms remain to be explained. Because inter-personal conflict is a heterogeneous phenomenon, investigation of the specific features of conflict that contribute to developmental pathways to emotional dysfunction and symptoms requires a process-oriented approach. In this project, we focus on brain responses to angry prosody in natural speech. We are studying young children’s neural processing of angry prosody, spoken by mothers and strangers, as a first step toward a future longitudinal study investigating how the neurocognitive processing of angry prosody mediates relations between conflict exposure in children and the development of anxiety- and anger-related symptoms.</p>
<p><strong>Collaborators</strong></p>
<ul>
<li>Pamela Cole, Penn State</li>
<li>Koraly Perez-Edgar, Penn State</li>
<li>Suzy Scherf, Penn State</li>
<li>Michelle Vigeant, Penn State</li>
</ul>
<p><strong>Support</strong></p>
<p>This project has received support from the Penn State <a href="http://ssri.psu.edu">Social Sciences Research Institute</a> and the National Institute of Mental Health under <a href="http://projectreporter.nih.gov/project_info_description.cfm?aid=8891792&amp;icde=26075719&amp;ddparam=&amp;ddvalue=&amp;ddsub=&amp;cr=2&amp;csb=default&amp;cs=ASC">R21-MH-104547</a>.</p>
<p><strong>Materials</strong></p>
<ul>
<li><a href="https://github.com/gilmore-lab/peep-II">PEEP II repo on GitHub</a>.</li>
<li><a href="https://github.com/gilmore-lab/PEEP-I">PEEP I repo on GitHub</a>.</li>
<li><a href="https://nyu.databrary.org/volume/248">PEEP I stimuli on Databrary</a></li>
</ul>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
